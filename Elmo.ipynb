{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dbc8ea7-7f9a-4eca-af6c-7db386cb3677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path \n",
    "import math\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea1f2e1-eb14-473a-b98c-0bded2674214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_concatenate_txt_files(main_folder):\n",
    "    # Initialize an empty string to store concatenated content\n",
    "    concatenated_content = \"\"\n",
    "\n",
    "    # Collect all txt file paths\n",
    "    txt_files = []\n",
    "    for root, _, files in os.walk(main_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                txt_files.append(os.path.join(root, file))\n",
    "\n",
    "    # Read and concatenate contents with a progress bar\n",
    "    for file_path in tqdm(txt_files, desc=\"Reading .txt files\"):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            concatenated_content += f.read() + \"\\n\"  # Add a newline after each file's content\n",
    "\n",
    "    return concatenated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7199706-ffb5-4d63-a3ce-4aa0c08bcfba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_sentences(sentences):\n",
    "    clean_sentences = []\n",
    "    for st in sentences:\n",
    "        tokens = st.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "        if tokens:\n",
    "            clean_sentences.append(tokens)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645fd269-6972-4f58-b758-01de925e4e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    # Regular expression to match sentence-ending punctuation\n",
    "    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!|\\n)\\s')\n",
    "    sentences = sentence_endings.split(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362f5c92-c63b-45a6-b77d-a55b2777e234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary building function\n",
    "def build_vocab(texts, vocab_size=30522):\n",
    "    token_counts = collections.Counter()\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r'\\w+|[^\\w\\s]', text.lower())\n",
    "        token_counts.update(tokens)\n",
    "    \n",
    "    vocab = {}\n",
    "    most_common_tokens = token_counts.most_common(vocab_size - 4)\n",
    "    for i, (token, count) in enumerate(most_common_tokens, 4): # Start from 4 to reserve special tokens\n",
    "        vocab[token] = i\n",
    "    vocab['[PAD]'] = 0\n",
    "    vocab['[UNK]'] = 1\n",
    "    vocab['[CLS]'] = 2\n",
    "    vocab['[SEP]'] = 3\n",
    "\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return vocab, inv_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b696f052-9405-487c-bc80-02d902961f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text, vocab):\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text.lower())\n",
    "    wordpiece_tokens = []\n",
    "    for token in tokens:\n",
    "        wordpiece_tokens.extend(wordpiece_tokenize(token, vocab))\n",
    "    return wordpiece_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66af5f8-899d-4dca-834b-62a09ec6d303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!|\\n)\\s')\n",
    "    sentences = sentence_endings.split(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379ecb79-574a-4501-8071-d40b28e3fe70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(text, vocab, max_length=128):\n",
    "    tokens = tokenize(text, vocab)\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "    token_ids = [vocab.get(token, vocab['[UNK]']) for token in tokens]\n",
    "    if len(token_ids) < max_length:\n",
    "        token_ids += [vocab['[PAD]']] * (max_length - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_length]\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c5f0b48-2f01-47f4-be88-69a046585094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoding function\n",
    "def decode(token_ids, inv_vocab):\n",
    "    tokens = [inv_vocab.get(token_id, '[UNK]') for token_id in token_ids]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11637db8-866b-4c44-8697-af44f82e8b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wordpiece_tokenize(word, vocab):\n",
    "    if word in vocab:\n",
    "        return [word]\n",
    "    tokens = []\n",
    "    for i in range(len(word)):\n",
    "        subword = word[:len(word) - i]\n",
    "        if subword in vocab:\n",
    "            tokens.append(subword)\n",
    "            remainder = word[len(word) - i:]\n",
    "            if remainder:\n",
    "                tokens.extend(wordpiece_tokenize(remainder, vocab))\n",
    "            break\n",
    "    if not tokens:\n",
    "        tokens = ['[UNK]']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89767613-337b-4417-b35f-156fb902dce5",
   "metadata": {},
   "source": [
    "## Reading an preparating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6793c274-ab8d-421c-9d21-ae4c25af1123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_folder = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef9dd9ca-3f64-483d-abc8-fd3cebdf6b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading .txt files: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "text = read_and_concatenate_txt_files(main_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1897e7eb-d0b0-4367-9cd1-638ab0b588ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nApril\\n\\nApril (Apr.) is the fourth month of the year in the Julian and Gregorian calendars, and come'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa4e869-20c0-43a6-aede-bbeccd8edb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = split_into_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1969fb-c310-446d-b138-d0eab4bacc37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nApril\\n',\n",
       " 'April (Apr.) is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May.',\n",
       " 'It is one of four months to have 30 days.',\n",
       " '',\n",
       " 'April always begins on the same day of the week as July, and additionally, January in leap years.',\n",
       " 'April always ends on the same day of the week as December.',\n",
       " '',\n",
       " 'April comes between March and May, making it the fourth month of the year.',\n",
       " 'It also comes first in the year out of the four months that have 30 days, as June, September and November are later in the year.',\n",
       " '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349ca67-0e42-4d67-8b41-a9e1de7946d1",
   "metadata": {},
   "source": [
    "## Creating Vocabulary\n",
    "\n",
    "Vocab is a dictionary were each word is asociated to a numerical index and viceverza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c48b9f68-99fd-4f37-a101-e24b693f69fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab, inv_vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962bef0-3bcc-4d9e-bab0-a80709bc114e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clarification of BERT style enconding\n",
    "\n",
    "The embedding layer in a neural network, including in the BERT model, does not interpret the numerical values of the token IDs as indicating any inherent ordering or value. Instead, it treats each unique token ID as an index into the embedding matrix, which is a learned parameter of the model.\n",
    "#### How embedding layer works:\n",
    "\n",
    "Token ID as indices: \n",
    "1. Each token ID is used as an indext to look up the corresponding row in the embeddings matrix.\n",
    "2. The embedding matrix has a shape of **(vocab_size, hidden_size)**, where each row represents the learned embedding of specific token. \n",
    "3. The numerical value of the token ID does not influence th embedding itself; it is merely a pinter to a specifc row in the matrix.\n",
    "\n",
    "Learning Embeddings:\n",
    "\n",
    "1. The embedding matrix is initialized randomly (or with some pre-defined initialization strategy) at the beginning of training.\n",
    "2. During training, the embeddings are updated based on the backpropagation of the loss.\n",
    "3. The position of a token ID in the embedding matrix (whether it is higher or lower) does not imply any hierarchical value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014511b8-eeb4-45e5-bdb2-421625a42019",
   "metadata": {},
   "source": [
    "## Encoding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a685035-7a06-43b4-85ab-47770abc14e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_sentences = [encode(sentence, vocab) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be057d25-82ef-43e6-b5bd-6201e5dc1924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_sentences = [decode(encoded_sentence, inv_vocab) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0ed57-682f-48f9-82d2-1503b6db01b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BERT Model:\n",
    "## Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c9e2996-4200-4efc-a71b-0c945d041125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ed5cb04-2029-4b64-82f0-3dff11d89efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, max_position_embeddings, type_vocab_size):\n",
    "        \n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(type_vocab_size, hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "        \n",
    "        word_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        \n",
    "        embeddings = word_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22a6ac-ce65-4877-bdca-4df9936f2869",
   "metadata": {},
   "source": [
    " #### Conde Explanation       \n",
    "1. __init__ is the constructor method that initializes the BertEmbeddings object.\n",
    "2. super(BertEmbeddings, self).__init__() calls the constructor of the parent class (nn.Module).\n",
    "3. self.word_embeddings: An embedding layer for token IDs. vocab_size is the number of unique tokens, and hidden_size is the size of each embedding vector.\n",
    "4. self.position_embeddings: An embedding layer for position IDs. max_position_embeddings is the maximum sequence length, and hidden_size is the size of each embedding vector.\n",
    "5. self.token_type_embeddings: An embedding layer for token type IDs. type_vocab_size is the number of token types (e.g., 2 for distinguishing between two sentences), and hidden_size is the size of each embedding vector.\n",
    "6. self.layer_norm: A layer normalization layer that normalizes the embeddings.\n",
    "8. self.dropout: A dropout layer that applies dropout regularization with a dropout rate of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5a100-8750-45ed-b799-9f49c9384c3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example of use for BERT type embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd5c1fb-256d-4345-861b-b737672fc149",
   "metadata": {},
   "source": [
    "To run the BERT type embedding we need the next parameters:\n",
    "1. vocab_size: The size of the vocabulary, which is the number of unique tokens in the vocabulary. It is set to len(vocab), where vocab is the dictionary mapping tokens to their corresponding IDs.\n",
    "2. hidden_size: The size of the hidden layers in the BERT model. For BERT base models, this is typically 768.\n",
    "3. max_position_embeddings: The maximum sequence length that the model can handle. For BERT base models, this is usually 512.\n",
    "4. type_vocab_size: The number of different token types. BERT uses token type embeddings to distinguish between different segments (e.g., sentences). The value 2 is used because BERT distinguishes between two segments (segment A and segment B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84d03ae1-a41f-4941-b3c8-ee957984fc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "hidden_size = 768\n",
    "max_position_embeddings = 512\n",
    "type_vocab_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ea46a-6075-4054-9c61-341a3b044dbf",
   "metadata": {},
   "source": [
    "The next line creates an instance of the BertEmbeddings class with the specified parameters. This class includes word embeddings, position embeddings, and token type embeddings, as well as layer normalization and dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b381f771-167a-4763-be24-20d1a79844d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertEmbeddings(vocab_size, hidden_size, max_position_embeddings, type_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66754912-3d0e-4fcd-8bf4-70614f47a5f0",
   "metadata": {},
   "source": [
    "Model use **'encoded_senteces'** that is the list where each inner list contains the token IDs for a sentences. Also **'torch.tensor(encoded_sentences)'** is converting the list fo encoded sentences into PyTorch tensor, which can be used as input to the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b7192-1d33-434b-ac20-414c4ba1968a",
   "metadata": {},
   "source": [
    "Then, next line use **encoded_sentences** as list of lsit where each inner list contains the tokens IDs for the sentences and the delcaration **torch.tensor(enconded_senteces)** converts the list of encoded sentences into a PyTorch tensor, with ca be used as input to the model.\n",
    "\n",
    "The toke_type_ids = torch.zeros_like(input_ids) use **torch.zeros_like(input_ids)** to create a tensor of zeros with the shape as **input_ids** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "141f64a9-acff-4518-842c-7b7a88afd495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_ids = torch.tensor(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6570a11a-eacc-4440-8247-6c69b7d6d908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#token_type_ids = torch.zeros_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c609a45e-d2cb-45e9-b4d7-ffc561bea881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BERT_embeddings = model(input_ids, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2256d49c-7dea-4533-848f-1f344ca714d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "tensor_embeddings_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "959b868e-642b-4a66-918b-13fa876a2caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96de513a-d718-4624-8a8e-221ae59b08af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3129eed-a4b5-40be-affc-8b41d194e715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 5/7455 [00:05<2:34:41,  1.25s/batch]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(encoded_sentences), batch_size), desc=\"Processing batches\", unit=\"batch\"):\n",
    "    batch_encoded_sentences = encoded_sentences[i:i + batch_size]\n",
    "    input_ids = torch.tensor(batch_encoded_sentences)\n",
    "    token_type_ids = torch.zeros_like(input_ids)  # Assume all tokens belong to the same segment\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = model(input_ids, token_type_ids)\n",
    "    tensor_embeddings_list.append(embeddings)\n",
    "    #print(f\"Batch {i // batch_size + 1} Embeddings shape:\", embeddings.shape)\n",
    "    #print(f\"Batch {i // batch_size + 1} Embeddings:\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d4f28-24bc-40a8-ba47-cb70de35406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embeddings = torch.cat(tensor_embeddings_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aeb258-e0b2-4c81-95cf-42075eb7d8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c23d0-688f-489f-8509-26418dfe869d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
